Your aim to is to build a mimimum viable product (MVP) for:  
1. Build a (MCP) [Model Context Protocol][1] for [Sonic FeeM (Fee Monetisation)][2]
2. Use MCP's [Rust SDK][3] to implement the [MCP Server][4]
3. MCP Server should fetch the sate of the Sonic from this bigquery dataset: `kunal-scratch.sonic_mainnet`
4. Make an assumption that sonic dataset schema is same as [this schema][5]
5. MCP should help analyse popularity of apps using FeeM compared to apps that don't use FeeM

Ensure that code is well documented with appropriate test coverage.
Make assumptions if required.  If unsure, seek clarification.

[1]: https://modelcontextprotocol.io/introduction
[2]: https://docs.soniclabs.com/funding/fee-monetization
[3]: https://github.com/modelcontextprotocol/rust-sdk
[4]: https://github.com/modelcontextprotocol/servers
[5]: https://cloud.google.com/blockchain-analytics/docs/schema#fantom_opera

----

Implement the following flow in apache beam data pipeline in python with Google Cloud Dataflow as runtime:
1. Listen for all the events emitted from this contract (0x0b5f073135df3f5671710f08b08c0c9258aecc35) deployed on Sonic Chain
2. The websocket endpoint to listen for these events is `wss://rpc.soniclabs.com`
3. Use Ethereum libraries to work with sonic chain
4. Decode individual events
5. Write to bigquery dataset `kunal-scratch.sonic-feem` and table `feem-events`
6. Create the table and dataset if one doesn't exist
7. In addition, the raw events from the RPC should also be batched (every 1000 blocks) and then written to GCS

Create a README.md file with instruction on how to work with the code.
Code should be well documented with appropriate test cases. Make assumptions if required and seek clarification if unclear